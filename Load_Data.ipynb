{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5c37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки numpy и pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# импортируем библиотеку datatime для работы с датами\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "\n",
    "# задаем некоторые опции библиотеки pandas, которые настраивают вывод\n",
    "pd.set_option('display.notebook_repr_html', False)     # задаем вывод в виде текста, а не HTML\n",
    "pd.set_option('display.max_columns', 8)                # устанавливаем отображение максимального количества стобцов\n",
    "pd.set_option('display.max_rows', 10)                  # устанавливаем отображение максимального количества строк\n",
    "pd.set_option('display.width', 80)                     # устанавливаеv максимальную ширину отображения в символах\n",
    "\n",
    "# импортируем библиотеку matplotlib для построения графиков\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85901b68",
   "metadata": {},
   "source": [
    "__Исследование CSV-файла__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a53c90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n",
      "['7/17/2014', '84.35', '84.63', '83.33', '83.63', '1974000']\n",
      "['7/16/2014', '83.77', '84.91', '83.66', '84.91', '1755600']\n",
      "['7/15/2014', '84.3', '84.38', '83.2', '83.58', '1874700']\n"
     ]
    }
   ],
   "source": [
    "# с помощью модуля csv посмотрим на первые пять строк CSV файла \n",
    "import csv\n",
    "with open('./msft.csv') as file:\n",
    "    reader = csv.reader(file, delimiter = ',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed055ac",
   "metadata": {},
   "source": [
    "__Чтение CSV файла в DataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90f55ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем csv в DataFrame\n",
    "msft = pd.read_csv('./msft.csv')\n",
    "msft.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91112a2",
   "metadata": {},
   "source": [
    "__Указание индекса столбца при чтении CSV файла__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc4d76e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Open   High    Low  Close   Volume\n",
       "Date                                          \n",
       "7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем столбец Date в качестве индекса\n",
    "msft = pd.read_csv('./msft.csv', index_col=0)\n",
    "msft.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e877a7a",
   "metadata": {},
   "source": [
    "__Вывод и спецификация типа данных__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92f0519c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# исследуем типы столбцов в нашем датафрейме\n",
    "msft.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f765f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date       object\n",
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# чтобы принудительно задать тип столбца, воспользуйтесь параметром dtype функции pd.read_csv(). Следующий программный код\n",
    "# преобразует стобец Volume в тип float.64 \n",
    "msft = pd.read_csv('./msft.csv',\n",
    "                   dtype = {'Volume' : np.float64})\n",
    "msft.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f9742",
   "metadata": {},
   "source": [
    "__Указание имен столбцов__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab0fdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close   volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Можно указать имена столбцов во время чтения данных, воспользовавшись параметром names \n",
    "# header = 0 задаёт строку заголовков, если этого не сделать pandas предположит, что первая строка является частью данных\n",
    "# и это в дальнейшем вызовет некоторые проблемы при обработке информации\n",
    "df = pd.read_csv('./msft.csv', \n",
    "                header = 0,\n",
    "                names = ['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f5e29",
   "metadata": {},
   "source": [
    "__Указание конкретных столбцов для загрузки__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85783062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Close\n",
       "Date            \n",
       "7/21/2014  81.93\n",
       "7/18/2014  83.35\n",
       "7/17/2014  83.63\n",
       "7/16/2014  84.91\n",
       "7/15/2014  83.58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# можно указать какие столбцы нужно загружать при чтении файла с помощью параметра usecols\n",
    "df2 = pd.read_csv('./msft.csv', usecols = ['Date', 'Close'], index_col = ['Date'])\n",
    "df2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc8642",
   "metadata": {},
   "source": [
    "__Сохранение датафрейма в CSV файл__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09547445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# с помощью метода .to_csv() объект DataFrame можно сохранить в CSV файл \n",
    "df2.to_csv('./msft_modified.csv', index_label = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "016f17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'Close']\n",
      "['7/21/2014', '81.93']\n",
      "['7/18/2014', '83.35']\n",
      "['7/17/2014', '83.63']\n",
      "['7/16/2014', '84.91']\n",
      "['7/15/2014', '83.58']\n"
     ]
    }
   ],
   "source": [
    "with open('./msft_modified.csv') as file:\n",
    "    reader = csv.reader(file, delimiter = ',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb01fe",
   "metadata": {},
   "source": [
    "__Работа с данными, в которых используются разделители полей__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4ea2b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Библиотека Pandas предлагает функцию pd.read_table() для упрощения чтения данных с разделителями полей\n",
    "df = pd.read_table('./msft.csv', sep = ',')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c77e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# у библиотеки pandas нет метода .to_table() аналогично методу .to_csv(). Однако метод .to_csv() можно применить\n",
    "# для записи данных с разделителями полей, в том числе и в тех случаях, когда в качестве разделителя вместо запятой\n",
    "# используется другой символ\n",
    "df.to_csv('./msft_piped.txt', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02866c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['|Date|Open|High|Low|Close|Volume']\n",
      "['0|7/21/2014|83.46|83.53|81.81|81.93|2359300']\n",
      "['1|7/18/2014|83.3|83.4|82.52|83.35|4020800']\n",
      "['2|7/17/2014|84.35|84.63|83.33|83.63|1974000']\n",
      "['3|7/16/2014|83.77|84.91|83.66|84.91|1755600']\n",
      "['4|7/15/2014|84.3|84.38|83.2|83.58|1874700']\n"
     ]
    }
   ],
   "source": [
    "# смотрим как произошло сохранение\n",
    "with open('./msft_piped.txt') as file:\n",
    "    reader = csv.reader(file, delimiter = ',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b638e949",
   "metadata": {},
   "source": [
    "__Обработка загрязненных данных, в которых используются разделители полей__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c856563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is fun because the data does not start on the first line', '', '', '', '', '']\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['', '', '', '', '', '']\n",
      "['And there is space between the header row and data', '', '', '', '', '']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n",
      "['7/17/2014', '84.35', '84.63', '83.33', '83.63', '1974000']\n"
     ]
    }
   ],
   "source": [
    "# смотрим первые 6 наблюдений файла msft2.csv\n",
    "with open('./msft2.csv') as file:\n",
    "    reader = csv.reader(file, delimiter = ',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 6):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46cc6100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# эту ситуацию можно разрешить с помощью параметра skiprows \n",
    "# считываем данные пропуская строки 0,2,3\n",
    "df = pd.read_csv('./msft2.csv', skiprows = [0, 2, 3])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7407f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n",
      "[]\n",
      "['Uh oh', ' there is stuff at the end.']\n"
     ]
    }
   ],
   "source": [
    "# смотрим файл msft_with_footer.csv\n",
    "with open('./msft_with_footer.csv') as file:\n",
    "    reader = csv.reader(file, delimiter = ',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a8bd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем пропустив две последние строки skip_footer\n",
    "df = pd.read_csv('./msft_with_footer.csv',\n",
    "                 skipfooter = 2,\n",
    "                 engine = 'python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b161df7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# чтобы не читать файл целиком и не занимать ресурсы, можно прочитать только несколько строк\n",
    "# считаем только первые 3 строчки\n",
    "pd.read_csv('./msft.csv', nrows = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c26565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        data   open   high    low  close   volume\n",
       "0   3/3/2014  80.35  81.31  79.91  79.97  5004100\n",
       "1  2/28/2014  82.40  83.42  82.17  83.42  2853200\n",
       "2  2/27/2014  84.06  84.63  81.63  82.00  3676800\n",
       "3  2/26/2014  82.92  84.03  82.43  83.81  2623600\n",
       "4  2/25/2014  83.80  83.80  81.72  83.08  3579100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# кроме того можно пропустить некторое число строк, а затем прочитать лишь какую то часть данных\n",
    "# пропускаем 100 строк, а затем считыыаем следующие 5 строк\n",
    "pd.read_csv('./msft.csv',\n",
    "            skiprows = 100,\n",
    "            nrows = 5,\n",
    "            header = 0,\n",
    "            names = ['data', 'open', 'high', 'low', 'close', 'volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ace50",
   "metadata": {},
   "source": [
    "__Чтение и запись данных в формате Excel__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf1e7254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем файл Excel \n",
    "# считываем только данные первого рабочего листа (mfst)\n",
    "df = pd.read_excel('./stocks.xlsx')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "997cb029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные другого листа из этого же файла\n",
    "df1 = pd.read_excel('./stocks.xlsx', sheet_name = 'aapl')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7618f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# все параметры которые мы рассмотрели для pd.read_csv() так же применимы к функции pd.read_excel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92a6d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Следующий программный код записывает только что полученные данные в файл tables2.xlsx\n",
    "# по умолчанию выполняется сохранение датафрейма в рабочем листе Sheet1\n",
    "df.to_excel('./tables2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf26b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# с помощью параметра sheet_name можно задать имя рабочего листа\n",
    "df.to_excel('./stocks_msft.xlsx', sheet_name = 'MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00db1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы записать несколько датафреймов в один и тот же файд Excel, по одному на каждый рабочий лист, воспользуйтесь объектом\n",
    "# ExelWriter и ключевым словом with\n",
    "from pandas import ExcelWriter\n",
    "with ExcelWriter('./all_stocks.xlsx') as writer:\n",
    "    df1.to_excel(writer, sheet_name = 'AAPL')\n",
    "    df.to_excel(writer, sheet_name = 'MSFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa8fea",
   "metadata": {},
   "source": [
    "__Чтение и запись JSON файлов__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "217fd5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Close': {'0': 81.93, '1': 83.35, '2': 83.63, '3': 84.91, '4': 83.58},\n",
      " 'Date': {'0': 1405900800000,\n",
      "          '1': 1405641600000,\n",
      "          '2': 1405555200000,\n",
      "          '3': 1405468800000,\n",
      "          '4': 1405382400000},\n",
      " 'High': {'0': 83.53, '1': 83.4, '2': 84.63, '3': 84.91, '4': 84.38},\n",
      " 'Low': {'0': 81.81, '1': 82.52, '2': 83.33, '3': 83.66, '4': 83.2},\n",
      " 'Open': {'0': 83.46, '1': 83.3, '2': 84.35, '3': 83.77, '4': 84.3},\n",
      " 'Volume': {'0': 2359300,\n",
      "            '1': 4020800,\n",
      "            '2': 1974000,\n",
      "            '3': 1755600,\n",
      "            '4': 1874700}}\n"
     ]
    }
   ],
   "source": [
    "# записываем данные Excel в JSON\n",
    "df[:5].to_json('./stocks.json')\n",
    "# теперь посмотрим на JSON файл \n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('./stocks.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "    \n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8e548df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# данные в формате JSON можно прочитать с помощью функции pd.read_json()\n",
    "df_from_json = pd.read_json('./stocks.json')\n",
    "df_from_json[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2155b93",
   "metadata": {},
   "source": [
    "__Чтение HTML файлов из интернета__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e3517c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "html5lib not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.fdic.gov/bank/individual/failed/banklist.html\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# читаем его\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m banks \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:1205\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[0;32m   1201\u001b[0m validate_header_arg(header)\n\u001b[0;32m   1203\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[1;32m-> 1205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:982\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    980\u001b[0m retained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flav \u001b[38;5;129;01min\u001b[39;00m flavor:\n\u001b[1;32m--> 982\u001b[0m     parser \u001b[38;5;241m=\u001b[39m \u001b[43m_parser_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflav\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m     p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py:931\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flavor \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbs4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml5lib\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAS_HTML5LIB:\n\u001b[1;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml5lib not found, please install it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAS_BS4:\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBeautifulSoup4 (bs4) not found, please install it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: html5lib not found, please install it"
     ]
    }
   ],
   "source": [
    "# Функция pd.read_html() считывает HTML файлы и записывает в один или несколько объектов DataFrame\n",
    "# задаем URL адрес HTML файла \n",
    "url = 'https://www.fdic.gov/bank/individual/failed/banklist.html'\n",
    "# читаем его\n",
    "banks = pd.read_html(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
